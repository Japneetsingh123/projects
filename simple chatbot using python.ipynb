{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#ignore the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#download package from nltk\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "#get artical url\n",
    "article= Article('https://simple.wikipedia.org/wiki/Light')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus=article.text\n",
    "#print\n",
    "print(corpus)\n",
    "#tokenization\n",
    "text=corpus\n",
    "sent_tokens=nltk.sent_tokenize(text)\n",
    "print(sent_tokens)\n",
    "#creating a dictionary to remove the punctuation\n",
    "remove_punct_dict=dict( (ord(punct),None) for punct in string.punctuation)\n",
    "print(string.punctuation)\n",
    "print(remove_punct_dict)\n",
    "#create a function to return lower case words \n",
    "def LemNormalize(text):\n",
    "  return nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
    "print(LemNormalize(text))\n",
    "#keywords for greetings\n",
    "greeting_input=[\"hi\",\"hello\",\"hey\",\"hola\"]\n",
    "greeting_response=[\"howdy\",\"hey there\",\"hi\",\"hello :)\"]\n",
    "def greeting(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower() in greeting_input:\n",
    "      return random.choice(greeting_response)\n",
    "def response(user_response):\n",
    " #user response and robo responce\n",
    "  #user_response=\"WHat is chronic disease\"\n",
    "  user_response=user_response.lower()\n",
    "  #print(user_response)\n",
    "  #robo response\n",
    "  robo_response=''\n",
    "  sent_tokens.append(user_response)\n",
    "  #print(sent_tokens)\n",
    "  tfidfvec=TfidfVectorizer(tokenizer=LemNormalize , stop_words='english')\n",
    "  tfidf=tfidfvec.fit_transform(sent_tokens)\n",
    "  #print(tfidf)\n",
    "  #get similarity score\n",
    "  val=cosine_similarity(tfidf[-1],tfidf)\n",
    "  #print(val)\n",
    "  idx=val.argsort()[0][-2]\n",
    "  flat=val.flatten()\n",
    "  flat.sort()\n",
    "  score=flat[-2]\n",
    "  #print(score)\n",
    "  if score==0:\n",
    "    robo_response=robo_response+\"sorry,i dont understand\"\n",
    "  else:\n",
    "    robo_response=robo_response+sent_tokens[idx]\n",
    "\n",
    "  sent_tokens.remove(user_response)\n",
    "  return robo_response\n",
    "greeting_input=[\"hi\",\"hello\",\"hey\",\"hola\"]\n",
    "greeting_response=[\"howdy\",\"hey there\",\"hi\",\"hello :)\"]\n",
    "def greeting(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower() in greeting_input:\n",
    "      return random.choice(greeting_response)\n",
    "flag=True\n",
    "print(\"hello!!! this is madmax,i can answer your queris related to light ,type bye to exit\")\n",
    "while(flag==True):\n",
    "  user_response=input(\"cherry:\")\n",
    "  #user_response=user_response.lower()\n",
    "  if(user_response!='bye'):\n",
    "    if(user_response=='thanks' or user_response=='thank you'):\n",
    "      flag=False\n",
    "      print(\"madmax: anytime :)\")\n",
    "    else:\n",
    "       if( greeting(user_response) != None):\n",
    "         print(\"madmax: \"+ greeting(user_response))\n",
    "       else:\n",
    "         print(\"madmax:\"+response(user_response))\n",
    "  else:\n",
    "    flag=False\n",
    "    print(\"madmax: see you later :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
